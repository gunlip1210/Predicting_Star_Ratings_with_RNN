{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umukHleUK1q6"
   },
   "source": [
    "# 변경 사항\n",
    "\n",
    "\n",
    "* BiLSTM으로 변경.\n",
    "* softmax 함수 겹치는 것 제거.\n",
    "* custom_acc, custom_loss_func 도입. (사용 선택)\n",
    "---\n",
    "[005] weighted cross entropy 미적용.\n",
    "* 005-1 | lr:0.0001 hidden layer: 4\n",
    "* 005-1 | lr:0.00005 hidden layer: 4\n",
    "\n",
    "[006] weighted cross entropy 적용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LFU5rVfW7Na"
   },
   "source": [
    "# 0. 제반 환경 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_aqbskLMVF4"
   },
   "outputs": [],
   "source": [
    "# 구글 드라이브 연결.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "MODEL_PATH = '/model005.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qi0GnFAwS5Zx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRandom Seed: 1210\n"
     ]
    }
   ],
   "source": [
    "# 데이터처리 관련 라이브러리.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re  # 정규표현식 사용 환경 제공.\n",
    "import string\n",
    "from collections import Counter\n",
    "# import seaborn as sns\n",
    "\n",
    "# 자연어처리 관련 라이브러리.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 딥러닝 관련 라이브러리.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm  # .ipynb에 최적화된 프로그래스 바.\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# 데이터셋 로딩용 라이브러리.\n",
    "!pip install -q datasets\n",
    "\n",
    "# LR sceduler 사용을 위한 hugging face의 transformers 설치.\n",
    "!pip install -q transformers\n",
    "\n",
    "# LR sceduler import.\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# Set pytorch random seed.\n",
    "seed = 1210\n",
    "torch.manual_seed(seed)\n",
    "print(\"Random Seed:\", seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oViPcfEBWvT6"
   },
   "source": [
    "# 1. Data 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k8uonsW1N9zv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'text'],\n",
      "    num_rows: 650000\n",
      "})\n",
      "{'label': 4, 'text': \"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\"}\n",
      "{'label': 1, 'text': \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\"}\n",
      "{'label': 3, 'text': \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\"}\n",
      "{'label': 3, 'text': 'Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June.  He will be missed very much.  \\\\n\\\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!'}\n",
      "{'label': 0, 'text': \"I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\"}\n",
      "{'label': 4, 'text': \"Top notch doctor in a top notch practice. Can't say I am surprised when I was referred to him by another doctor who I think is wonderful and because he went to one of the best medical schools in the country. \\\\nIt is really easy to get an appointment. There is minimal wait to be seen and his bedside manner is great.\"}\n",
      "{'label': 4, 'text': 'Dr. Eric Goldberg is a fantastic doctor who has correctly diagnosed every issue that my wife and I have had. Unlike many of my past doctors, Dr. Goldberg is very accessible and we have been able to schedule appointments with him and his staff very quickly. We are happy to have him in the neighborhood and look forward to being his patients for many years to come.'}\n",
      "{'label': 0, 'text': \"I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\\\n\\\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an $800.00 bill for the blood work. I can't pay for my bill because I'm a student and don't have any cash flow at this current time. I can't believe the Doctor wouldn't give me a heads up to make sure my insurance would cover work that wasn't necessary and was strictly preventative. The office can't do anything to help me cover the bill. In addition, the office staff said the onus is on me to make sure my insurance covers visits. Frustrating situation!\"}\n",
      "{'label': 1, 'text': 'Wing sauce is like water. Pretty much a lot of butter and some hot sauce (franks red hot maybe).  The whole wings are good size and crispy, but for $1 a wing the sauce could be better. The hot and extra hot are about the same flavor/heat.  The fish sandwich is good and is a large portion, sides are decent.'}\n",
      "{'label': 2, 'text': \"Decent range somewhat close to the city.  The mats are pretty solid; however, the grass range needs to be tended too.  It's like hitting out of US Open type rough...not very amenable to practicing.  Which kind of defeats the purpose of going to a golf range...Still gets 3 stars because the range is lit up at night which is excellent for those of us who are addicted to this amazing game, but are somewhat short on time (having a job kinda sucks sometimes, no?).\"}\n",
      "Dataset({\n",
      "    features: ['label', 'text'],\n",
      "    num_rows: 50000\n",
      "})\n",
      "{'label': 0, 'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'}\n",
      "{'label': 0, 'text': \"Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing.\"}\n",
      "{'label': 0, 'text': 'All I can say is the worst! We were the only 2 people in the place for lunch, the place was freezing and loaded with kids toys! 2 bicycles, a scooter, and an electronic keyboard graced the dining room. A fish tank with filthy, slimy fingerprints smeared all over it is there for your enjoyment.\\\\n\\\\nOur food came... no water to drink, no tea, medium temperature food. Of course its cold, just like the room, I never took my jacket off! The plates are too small, you food spills over onto some semi-clean tables as you sit in your completely worn out booth seat. The fried noodles were out of a box and nasty, the shrimp was mushy, the fried rice was bright yellow.\\\\n\\\\nWe asked for water, they brought us 1 in a SOLO cup for 2 people. I asked for hot tea, they said 10 minutes. What Chinese restaurant does not have hot tea available upon request?\\\\n\\\\nOver all.... my first and last visit to this place. The only good point was that it was cheap, and deservingly so.'}\n",
      "{'label': 0, 'text': \"I have been to this restaurant twice and was disappointed both times. I won't go back. The first time we were there almost 3 hours. It took forever to order and then forever for our food to come and the place was empty. When I complained the manager was very rude and tried to blame us for taking to long to order. It made no sense, how could we order when the waitress wasn't coming to the table? After arguing with me he ended up taking $6 off of our $200+ bill. Ridiculous. If it were up to me I would have never returned. Unfortunately my family decided to go here again tonight. Again it took a long time to get our food. My food was cold and bland, my kids food was cold. My husbands salmon was burnt to a crisp and my sister in law took one bite of her trout and refused to eat any more because she claims it was so disgusting. The wedding soup and bread were good, but that's it! My drink sat empty throughout my meal and never got refilled even when I asked. Bad food, slow service and rude managers. I'll pass on this place if my family decides to go again. Not worth it at all with all the other good Italian options around.\"}\n",
      "{'label': 0, 'text': \"Food was NOT GOOD at all! My husband & I ate here a couple weeks ago for the first time. I ordered a salad & basil pesto cream pasta & my husband ordered the spinach & feta pasta. The salad was just a huge plate of spring mix (nothing else in it) with WAY to much vinegar dressing. My lettuce was drowning in the vinegar. My pesto pasta had no flavor (did not taste like a cream sauce to me) & the pesto was so runny/watery & way too much sauce not enough noodles. My husband's pasta had even less flavor than mine. We ate about a quarter of the food & couldn't even finish it. We took it home & it was so bad I didn't even eat my leftovers. And I hate wasting food!! Plus the prices are expensive for the amount of food you get & of course the poor quality. Don't waste your time eating here. There are much better Italian restaurants in Pittsburgh.\"}\n",
      "{'label': 2, 'text': \"This is a tiny Starbucks and it locations like this (although cute) makes you wonder if your really meant to hang out or just grab your coffee and leave. Leaving is always a good idea at this location anyway since you have a nice fountain in the back with benches and it is a central part of the Waterfront Shopping. \\\\n\\\\nStarbuck isn't my favorite coffee chain by any means. Is it just me or do all Starbuck coffees taste a little burnt and bitter? No matter how trendy, cool and upscale their establishments are I can't get around the yicky tasting bitterness of Staryucks regular coffees. Talk about over roasting a bean...Maybe something has changed with their regular coffee but I have not drank it in about a year. I am not one for soy caramel latte foofy stuff. Still I'll give the establishment tres estrellas for the fact that their espresso is acceptable and doesn't taste half as bad as the regular coffee bean.\"}\n",
      "{'label': 1, 'text': 'Typical Starbucks coffee chain. 2 things I dont like about this Starbucks: \\\\n\\\\n1. Ive been there twice and both times the place has been dirty, compared to the other Starbucks I have been in.\\\\n\\\\n2. If you have to use the bathroom, they give you a key thats attached to this nasty bottle. Im pretty sure they dont clean that bottle after every use or even nightly.\\\\n\\\\nAside from that, good coffee and fast/friendly service.'}\n",
      "{'label': 3, 'text': \"So.Much.Fun! \\\\n\\\\nI WISH I could play a song at the drop of a hat. Too bad I never took piano lessons and I'd probably end up mumbling half the lyrics other than the chorus. Unless it's Salt n' Pepa's Shoop. \\\\n\\\\nThis is a really great place to go when you have out of town guests or are looking for a fun place to take someone for a birthday celebration or a fun night out. It's just something different to do other than boozing it up at the bars on a Saturday night. \\\\n\\\\nKeep in mind you'll be paying around a $5-10 cover plus whatever drinks and food you get. The good thing is the food is coming from the attached Rock Bottom Brewery. So a lot of it is restaurant quality good. Plus the brewery beer is actually pretty good! OF course you will be paying restaurant price drinks...so of course they're up charged a bit. But you do pay for the whole experience....so you gotta get into the spirit with some spirits! \\\\n\\\\nThe guys who play are incredibly talented. There's 2 guys that will take requests and play songs on the piano. They pretty much play ANYTHING you ask. Contemporary songs, throw back songs, fight songs, rap songs, pop songs. You name it, they play it. \\\\n\\\\nMy favorite part is when they switch out to another two guys. They'll all four get on stage and play two piano's, a guitar and drums. They usually rock out with some fun familiar songs (um, Journey, of course!). \\\\n\\\\nThe birthday song is seriously the best. They sing to you....and call you some names....with expletives. But in a totally nice way of course. You just have to go!\"}\n",
      "{'label': 3, 'text': 'My friend is a piano teacher, so I took it as a good sign that Sing Sing would be quality stuff. It was her birthday, and I didn\\'t really know anything about dueling piano bars. I was picturing glossy black grand pianos with glittering notes, pianists in black jackets and crystal glasses full of red wine. I am really, really glad I was wrong. \\\\n\\\\nIt was gritty, bawdy and quintessentially Pittsburgh. First off, the pianos are scuffed to hell, considering the number of tipsy people who sit on them nightly while being mildly humiliated. The musicians hammer away at them, and they\\'re covered with N@ and Sing Sing stickers. It\\'s obvious they\\'ve been well-loved. The music is anything but the elevator music I was picturing; it\\'s rock, hip-hop, oldies, pop, and just about any genre imaginable thanks to the request system (send up a piece of paper with some money) and the amazing repertoire of the musicians. For instance, \\\\\"Rubber Ducky\\\\\" and \\\\\"Gangsta\\'s Paradise\\\\\" were both featured when I was there, and both performed impeccably. They also honored a request for a Taylor Swift song only to receive $30 and a request for \\\\\"anything else,\\\\\" which they promptly followed. The musicians also do funny versions of popular songs, and throw in things like \\\\\"yinz\\\\\" instead of \\\\\"you.\\\\\"\\\\n\\\\nI saw in awe of the performers for a decent portion of the night. It must take a particularly special type of person to put on a show like this, considering the energy, confidence, wit, empathy, boldness, silliness, cleverness, and sheer talent a job like this requires. They rotate performers in and out so there\\'s not even an intermission. I\\'ve read comments about the baseness of the humor, but I had no doubt the guys up on stage were intelligent dudes. They had great personalities: one was about 140 pounds, cheeky, and quick-witted. He acted out every sport in the winter olympics, and was pretty into this 90-something-year-old lady in the audience called Joan. The other had crazy hair and bright blue Chucks, beatboxed as well as he sang, and made it point to play a handful of songs for my friend\\'s birthday. \\\\\"I think Ray Charles is the most soulful guy of all time,\\\\\" he said when she requested him.\\\\n\\\\nThere were tons of people celebrating birthdays, and one big bachelorette party the Saturday night I was there. The performers bring the birthday boy/girl, bachelor/bachelorette, etc. on stage (for a $20 tip, which is pretty easy to scrounge up among friends) and humiliate the hell out of them, i.e. this is not the place to be if you can\\'t laugh at yourself. My friend had a short dress on when she sat on the piano, and they sang a three-minute song about her vagina.\\\\n\\\\nLuckily, the show eclipsed the bad service and overpriced, weak drinks, because those did feature heavily throughout the night. The rest of the staff was friendly, however, and I stumbled on the door guy singing and dancing by himself, which made me smile.\\\\n\\\\nSing Sing is definitely not an every weekend type of thing (much like Hofbr\\\\u00e4uhaus), but is a splendid way to celebrate a special occasion. Definitely belongs on every required Pittsburgh experiences list.'}\n",
      "{'label': 2, 'text': \"Stopped by on a Mon evening after trying to dine at Smoke Taqueria which is closed Mondays. Parking on street in front or behind off Hay St. Super friendly bartender. In warmer months they have huge outdoor area & big screen & upstairs cornhole game area. Okay draft beer selection and big bottle selection. Tried the italian club which was really good - two of us split one. Also tried sweet potato fries - amazingly good! Home made chips w bleu were overpowered by sauce. Bathroom was in need of plaster and wall repairs & was grossed out by toilet brush/holder on a shelf near toilet at eye level. Bet it's a fun place in warmer months.\"}\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 로딩.\n",
    "from datasets import load_dataset  # Huggingface의 datasets 라이브러리를 이용.\n",
    "\n",
    "# Yelp Review Full 데이터셋 불러오기.\n",
    "# 음식점, 서비스, 장소 등 비즈니스에 대한 텍스트 후기와 별점(0-4)이 포함된 데이터셋.\n",
    "dataset_train = load_dataset(\"yelp_review_full\", split=\"train\")\n",
    "dataset_test = load_dataset(\"yelp_review_full\", split=\"test\")\n",
    "\n",
    "# 데이터셋의 예시 확인.\n",
    "print(dataset_train)\n",
    "for i in range(10):\n",
    "    print(dataset_train[i])\n",
    "print(dataset_test)\n",
    "for i in range(10):\n",
    "    print(dataset_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F5A-VAEdVVg1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of all data: 700000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th># of data</th>\n",
       "      <td>140000</td>\n",
       "      <td>140000</td>\n",
       "      <td>140000</td>\n",
       "      <td>140000</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1       2       3       4\n",
       "# of data  140000  140000  140000  140000  140000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas DataFrame 형태로 변환.\n",
    "train_df = pd.DataFrame(dataset_train)\n",
    "test_df = pd.DataFrame(dataset_test)\n",
    "\n",
    "# train_df와 test_df를 하나의 DataFrame으로 세로로 연결.\n",
    "data_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Train data 65만개, Test data 5만개, 총 70만개, 별점 별 14만개.\n",
    "# 별점 별 동일 개수.\n",
    "data_count = [[data_df.label.value_counts()[0],\n",
    "        data_df.label.value_counts()[1],\n",
    "        data_df.label.value_counts()[2],\n",
    "        data_df.label.value_counts()[3],\n",
    "        data_df.label.value_counts()[4]]]\n",
    "print(\"# of all data:\", data_df.shape[0])\n",
    "pd.DataFrame(data_count, index=[\"# of data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsrsby6lXEZE"
   },
   "source": [
    "# 2. Data 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qO72-3LDbmGq"
   },
   "source": [
    "## 2-a. Data Cleaning.\n",
    "unicode characters, puncutation, stopwords 제거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HCEkd-NCWOwH"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0782367bd0a54b429ede540fda8381b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>dr. goldberg offers everything i look for in a...</td>\n",
       "      <td>dr goldberg offers everything look general pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "      <td>unfortunately frustration dr goldberg patient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "      <td>going dr goldberg 10 years think one 1st patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Got a letter in the mail last week that said D...</td>\n",
       "      <td>got letter mail last week said dr goldberg mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>know dr goldberg like moving arizona let tell ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      4  dr. goldberg offers everything i look for in a...   \n",
       "1      1  Unfortunately, the frustration of being Dr. Go...   \n",
       "2      3  Been going to Dr. Goldberg for over 10 years. ...   \n",
       "3      3  Got a letter in the mail last week that said D...   \n",
       "4      0  I don't know what Dr. Goldberg was like before...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  dr goldberg offers everything look general pra...  \n",
       "1  unfortunately frustration dr goldberg patient ...  \n",
       "2  going dr goldberg 10 years think one 1st patie...  \n",
       "3  got letter mail last week said dr goldberg mov...  \n",
       "4  know dr goldberg like moving arizona let tell ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", text) # Removing Unicode Characters\n",
    "    text = ''.join([c for c in text if c not in string.punctuation]) # Remove punctuation\n",
    "\n",
    "    # Removing Stopwords\n",
    "    # stop words are common words within sentences that do not add value\n",
    "    # and thus can be eliminated when cleaning for NLP prior to analysis.\n",
    "    # e.g., 'the', 'was'\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "tqdm.pandas()  # tqdm을 이용하여 진행률 표시하기 위해 초기화.\n",
    "data_df['cleaned_text'] = data_df['text'].progress_apply(data_preprocessing)  # cleaned_text 열을 생성하면서 진행률 표시.\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OlS5BCxeRbl"
   },
   "source": [
    "# 3. Data 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W5nLzoVeuf0"
   },
   "source": [
    "## 3-a. Create Vocab-Int mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20jAtGcKfwvs"
   },
   "source": [
    "단어 추출 후, 빈도를 계산하여 순서대로 *sorted_words*에 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fMC57pDUemuU"
   },
   "outputs": [],
   "source": [
    "corpus = [word for text in data_df['cleaned_text'] for word in text.split()]\n",
    "count_words = Counter(corpus)\n",
    "sorted_words = count_words.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfllwH2rf2Zz"
   },
   "source": [
    "Vocabulary 생성.\n",
    "One-hot vectoer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NFkD4R6ZgVkA"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc98b199766a4184a64298e7de982ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting text to integers:   0%|          | 0/700000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[913, 38405, 1310, 105, 165, 1011, 13744, 21, 487, 630, 234, 9467, 53, 8, 880, 3516, 10242, 176, 1420, 2327, 40493, 1583, 994, 1390, 691, 85, 1654, 131, 3437, 6, 13831, 68, 13559, 234, 68, 34, 14, 131, 427, 258, 50, 1325, 14, 8373, 5381]]\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
    "\n",
    "# tqdm을 사용하여 cleaned_text 열의 각 텍스트에 대한 진행률 표시.\n",
    "text_int = []\n",
    "\n",
    "# tqdm을 이용해 cleaned_text의 각 항목에 대해 진행률 표시.\n",
    "for text in tqdm(data_df['cleaned_text'], desc=\"Converting text to integers\"):\n",
    "    r = [vocab_to_int[word] for word in text.split()]\n",
    "    text_int.append(r)\n",
    "\n",
    "# 첫 번째 텍스트의 정수 표현 확인.\n",
    "print(text_int[:1])\n",
    "\n",
    "# DataFrame에 정수 표현을 추가.\n",
    "data_df['text_int'] = text_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXRsHVIPg8Bg"
   },
   "source": [
    "# 4. Padding and Truncating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E74qg4C7kU-G"
   },
   "source": [
    "## 4-a. Analyze the text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fMzmhkPvkW8S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    700000.000000\n",
      "mean         70.655090\n",
      "std          63.825577\n",
      "min           0.000000\n",
      "25%          28.000000\n",
      "50%          52.000000\n",
      "75%          92.000000\n",
      "max        1002.000000\n",
      "Name: text_len, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = [len(x) for x in text_int]\n",
    "data_df['text_len'] = text_len\n",
    "\n",
    "print(data_df[\"text_len\"].describe())\n",
    "\n",
    "data_df[\"text_len\"].hist(bins = range(min(data_df[\"text_len\"]), max(data_df[\"text_len\"]) + 50, 50))\n",
    "plt.title('Text length distribution', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03_HDabDkv6-"
   },
   "source": [
    "## 4-b. Padding / Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Rw2MAXxBlS52"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c886aa5b2d44f7a6e856c6b56253a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Padding reviews:   0%|          | 0/700000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Padding(review_int, seq_len):\n",
    "    '''\n",
    "    0으로 패딩\n",
    "    Return features of text_int, where each text is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    # Initialize the features array with zeros.\n",
    "    features = np.zeros((len(review_int), seq_len), dtype=int)\n",
    "\n",
    "    # tqdm을 사용하여 패딩 작업의 진행률 표시.\n",
    "    for i, text in tqdm(enumerate(review_int), total=len(review_int), desc=\"Padding reviews\"):\n",
    "        if len(text) <= seq_len:\n",
    "            zeros = list(np.zeros(seq_len - len(text)))\n",
    "            new = text + zeros\n",
    "        else:\n",
    "            new = text[:seq_len]\n",
    "        features[i, :] = np.array(new)\n",
    "\n",
    "    return features\n",
    "\n",
    "# seq_len 200으로 설정하고 Padding 함수 호출.\n",
    "features = Padding(text_int, 200)\n",
    "# print(features[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QocR7ZjQlwhn"
   },
   "source": [
    "# 5. Data split\n",
    "test : valid : test = 12 : 1 : 1 비율로 dataset 분리."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ivH7aK4nmorK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Train dataset: 600000\n",
      "# of Valid dataset: 50000\n",
      "# of Test dataset: 50000\n"
     ]
    }
   ],
   "source": [
    "# Train set 분리\n",
    "X_train, X_remain, y_train, y_remain = train_test_split(features, data_df['label'].to_numpy(), test_size=1/7, random_state=1)\n",
    "\n",
    "# Valid set, Test set 분리\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_remain, y_remain, test_size=0.5, random_state=1)\n",
    "\n",
    "print(\"# of Train dataset:\", len(X_train))\n",
    "print(\"# of Valid dataset:\", len(X_valid))\n",
    "print(\"# of Test dataset:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "695kEuL6ozWb"
   },
   "source": [
    "# 6. Set hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1dc2dx48o4bB"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64  # 16, 32, 64, 128 등 해보고 결과 비교.\n",
    "\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 256\n",
    "N_LAYERS = 4\n",
    "DROPOUT_PROB = 0.3  # 0.3 - 0.5 정도. 데이터셋이 많을 수록 작은 값 사용하는 편.\n",
    "\n",
    "SEMI_DIFF_SCORE = 0.2  # predict label과 real label이 1만큼 차이 날 때, 몇 점으로 매길 것인지. 완전 불일치 0. 완전 일치 1.\n",
    "\n",
    "VOCAB_SIZE = len(vocab_to_int) + 1  # 고정.\n",
    "OUTPUT_SIZE = 5  # 고정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BErVpINqpDH_"
   },
   "source": [
    "# 7. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HDnWNoLcpuAc"
   },
   "outputs": [],
   "source": [
    "# trun our data into tensor dataset\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))\n",
    "\n",
    "# build dataloaders\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True) # drop_last. 마지막 배치에서 데이터셋이 부족하면 무시.\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H02bDzs4NCyB"
   },
   "source": [
    "# 8. Deep learning Model\n",
    "RNN with BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tHj2Lnl9NK2-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# GPU vs. CPU 선택.\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, use CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Mz9GXfCmOEks"
   },
   "outputs": [],
   "source": [
    "# Model Block 정의\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Dropout and fully connected layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        # self.softmax = nn.Softmax(dim=1)  # Softmax for multi-class output\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Embedding and LSTM output\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        # Stack up LSTM outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        # Dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # Apply softmax to output layer for multi-class classification\n",
    "        # softmax_out = self.softmax(out)\n",
    "\n",
    "        # Reshape to batch size\n",
    "        # softmax_out = softmax_out.view(batch_size, -1, self.output_size)\n",
    "        # softmax_out = softmax_out[:, -1]  # Select final time step's output\n",
    "\n",
    "        # return softmax_out, hidden\n",
    "\n",
    "        # Softmax 제거 버전.\n",
    "        # Reshape to batch size\n",
    "        out = out.view(batch_size, -1, self.output_size)\n",
    "        out = out[:, -1]  # Select final time step's output\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros((self.n_layers*2, batch_size, self.hidden_dim)).to(device)  # *2 Bidirection 이므로\n",
    "        c0 = torch.zeros((self.n_layers*2, batch_size, self.hidden_dim)).to(device)  # *2 Bidirection 이므로\n",
    "        hidden = (h0, c0)\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "78zMc07eQe9p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): Embedding(245119, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=4, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model 생성.\n",
    "model = LSTM(VOCAB_SIZE, OUTPUT_SIZE, EMBED_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgIYHO-3Q77k"
   },
   "source": [
    "# 9. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIdyPffzSo2X"
   },
   "source": [
    "## 9-a. 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-K6L2D5VlHY"
   },
   "outputs": [],
   "source": [
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, exponent=2):\n",
    "        super(WeightedCrossEntropyLoss, self).__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.alpha = alpha\n",
    "        self.exponent = exponent\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # 기본 CrossEntropy 손실 계산 (각 샘플마다)\n",
    "        ce_loss = self.cross_entropy(pred, target)\n",
    "        \n",
    "        # 예측 클래스 추출\n",
    "        _, pred_classes = torch.max(pred, dim=1)\n",
    "        \n",
    "        # 예측 클래스와 실제 클래스의 차이 계산\n",
    "        difference = torch.abs(pred_classes - target)\n",
    "        \n",
    "        # 비선형 가중치 적용 (차이에 대해 거듭제곱과 alpha 가중치 적용)\n",
    "        weights = (self.alpha * (difference.float() ** self.exponent)).detach()\n",
    "        \n",
    "        # 가중치가 적용된 손실\n",
    "        weighted_loss = ce_loss * weights\n",
    "        \n",
    "        # 평균 손실 반환\n",
    "        return weighted_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhJ4SnybTj-f"
   },
   "outputs": [],
   "source": [
    "lr = 0.0001  # learning rate.\n",
    "wd = 0.01  # weight decay.\n",
    "loss_func = nn.CrossEntropyLoss()  # 다중 클래스 분류를 위한 손실 함수.\n",
    "custom_loss_func = CustomLoss()    # 다중 클래스 분류를 위한 손실 함수. 가중치 고려.\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "clip = 5 # for ameliorating the exploding-gradient problem.\n",
    "epochs = 15\n",
    "\n",
    "total_steps = len(train_loader) * epochs\n",
    "warmup_steps = int(0.15 * total_steps)  # 예: 15%를 warmup 단계로 설정\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HXPYNKpjRF8k"
   },
   "outputs": [],
   "source": [
    "def acc(pred, label):\n",
    "    # 각 샘플에 대해 가장 높은 확률을 가진 클래스를 예측 클래스로 변환\n",
    "    _, pred_classes = torch.max(pred, dim=1)  # 예측 확률의 최대값 인덱스를 클래스 레이블로 변환\n",
    "    correct = torch.sum(pred_classes == label).item()  # 예측이 실제 레이블과 일치하는 수를 계산\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vMKuTqN2IdAq"
   },
   "outputs": [],
   "source": [
    "def custom_acc(pred, label):\n",
    "    # 각 샘플에 대해 가장 높은 확률을 가진 클래스를 예측 클래스로 변환\n",
    "    _, pred_classes = torch.max(pred, dim=1)  # 예측 확률의 최대값 인덱스를 클래스 레이블로 변환\n",
    "\n",
    "    # 예측과 실제 레이블 간의 차이를 계산\n",
    "    difference = torch.abs(pred_classes - label)\n",
    "\n",
    "    # 정확하게 일치하면 1, 1만큼 차이나면 0.3, 그 외에는 0 점수 부여\n",
    "    scores = torch.where(difference == 0, 1.0, torch.where(difference == 1, SEMI_DIFF_SCORE, 0.0))\n",
    "\n",
    "    # 전체 점수의 합계를 계산\n",
    "    total_score = torch.sum(scores).item()\n",
    "\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KkUbwunjSure"
   },
   "outputs": [],
   "source": [
    "each_epoch_tr_loss,each_epoch_vl_loss = [],[]\n",
    "each_epoch_tr_acc,each_epoch_vl_acc = [],[]\n",
    "each_epoch_tr_custom_acc,each_epoch_vl_custom_acc = [],[]\n",
    "each_epoch_lr = []\n",
    "valid_loss_min = np.Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9KU3PpjS_Y1"
   },
   "source": [
    "## 9-b. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTxD1vU5TCOd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae20980cc55544799388dd0f95ccbb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"Epoch\", epoch+1)\n",
    "\n",
    "    ## TRAINING ##\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    train_custom_acc = 0.0\n",
    "    model.train()  # 모델을 훈련 모드로 설정\n",
    "    h = model.init_hidden(BATCH_SIZE)  # 초기 hidden state 설정\n",
    "\n",
    "    print(\"Train Step\")\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        h = tuple([each.data for each in h])  # 이전 hidden state 데이터 유지\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # GPU 또는 CPU로 이동\n",
    "\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        # 손실 계산 및 역전파\n",
    "        loss = loss_func(output, labels)  # ----------\n",
    "        # loss = custom_loss_func(output, labels)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # 정확도 계산\n",
    "        accuracy = acc(output, labels)\n",
    "        custom_accuracy = custom_acc(output, labels)\n",
    "        train_acc += accuracy\n",
    "        train_custom_acc += custom_accuracy\n",
    "\n",
    "        # exploding gradient 문제를 예방\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        # LR scheduler를 사용한다면,\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"Valid Step\")\n",
    "    ## EVALUATION ##\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    val_custom_acc = 0.0\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    val_h = model.init_hidden(BATCH_SIZE)  # 초기 hidden state 설정\n",
    "\n",
    "    for inputs_v, labels_v in tqdm(valid_loader):\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "        inputs_v, labels_v = inputs_v.to(device), labels_v.to(device)  # GPU 또는 CPU로 이동\n",
    "\n",
    "        output_v, val_h = model(inputs_v, val_h)\n",
    "        val_loss = loss_func(output_v, labels_v)  # ----------\n",
    "        # val_loss = custom_loss_func(output_v, labels_v)\n",
    "\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "        accuracy = acc(output_v, labels_v)\n",
    "        custom_accuracy = custom_acc(output_v, labels_v)\n",
    "        val_acc += accuracy\n",
    "        val_custom_acc += custom_accuracy\n",
    "\n",
    "    # 평균 손실 및 정확도 계산\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc / len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc / len(valid_loader.dataset)\n",
    "    epoch_train_custom_acc = train_custom_acc / len(train_loader.dataset)\n",
    "    epoch_val_custom_acc = val_custom_acc / len(valid_loader.dataset)\n",
    "\n",
    "    # 손실 및 정확도 기록\n",
    "    each_epoch_tr_loss.append(epoch_train_loss)\n",
    "    each_epoch_vl_loss.append(epoch_val_loss)\n",
    "    each_epoch_tr_acc.append(epoch_train_acc)\n",
    "    each_epoch_vl_acc.append(epoch_val_acc)\n",
    "    each_epoch_tr_custom_acc.append(epoch_train_custom_acc)\n",
    "    each_epoch_vl_custom_acc.append(epoch_val_custom_acc)\n",
    "    each_epoch_lr.append(scheduler.get_last_lr())\n",
    "\n",
    "    # print(f'Epoch {epoch + 1}')\n",
    "    print(\"learning rate:\", scheduler.get_last_lr())\n",
    "    print(f'train_loss : {epoch_train_loss:.4f} | val_loss : {epoch_val_loss:.4f}')\n",
    "    print(f'train_accuracy : {epoch_train_acc * 100:.2f}% | val_accuracy : {epoch_val_acc * 100:.2f}%')\n",
    "    print(f'train_custom_accuracy : {epoch_train_custom_acc * 100:.2f}% | val_custom_accuracy : {epoch_val_custom_acc * 100:.2f}%')\n",
    "\n",
    "    # 검증 손실이 줄어들면 모델 저장\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print('Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...'.format(valid_loss_min, epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n",
    "\n",
    "    print(25 * '==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGYrCc0YUyNF"
   },
   "source": [
    "# 10. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVoEE6hrUz39"
   },
   "outputs": [],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = []  # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "test_h = model.init_hidden(BATCH_SIZE)\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in tqdm(test_loader):\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    test_h = tuple([each.data for each in test_h])\n",
    "\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    output, test_h = model(inputs, test_h)\n",
    "\n",
    "    # calculate loss\n",
    "    test_loss = loss_func(output, labels)  # CrossEntropyLoss는 logits을 사용하므로 squeeze하지 않음\n",
    "    test_losses.append(test_loss.item())\n",
    "\n",
    "    # convert output probabilities to predicted class (0 to 4)\n",
    "    pred = torch.argmax(output, dim=1)  # 가장 높은 확률을 가진 클래스 인덱스 선택\n",
    "\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.view_as(pred))  # 예측과 실제 라벨 비교\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.4f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct / len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6zPd0fSjdeU"
   },
   "outputs": [],
   "source": [
    "print(each_epoch_tr_loss)\n",
    "print(each_epoch_vl_loss)\n",
    "print(each_epoch_tr_acc)\n",
    "print(each_epoch_vl_acc)\n",
    "print(each_epoch_tr_custom_acc)\n",
    "print(each_epoch_vl_custom_acc)\n",
    "print(each_epoch_lr)\n",
    "\n",
    "# 첫 번째 y축에 손실(loss)을 플로팅\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(each_epoch_vl_loss, color='blue', marker='o', label=\"Validation Loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Validation Loss\", color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# 두 번째 y축에 정확도(accuracy)를 플로팅\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(each_epoch_vl_acc, color='red', marker='x', linestyle='--', label=\"Validation Accuracy\")\n",
    "ax2.set_ylabel(\"Validation Accuracy\", color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# 제목 추가\n",
    "plt.title(f\"Validation Loss and Accuracy (lr: {lr}, hidden layer: {HIDDEN_DIM})\")\n",
    "\n",
    "# 그래프 표시\n",
    "fig.tight_layout()  # 겹침 방지\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7XF-8_eyXR_"
   },
   "source": [
    "## 10-append. 학습된 모델 불러오기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ep-q09ZJyZf6"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
